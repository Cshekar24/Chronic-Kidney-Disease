{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('chronic_kidney_disease.csv', na_values=['?','\\t?'])\n",
    "df.head(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to remove all tab spaces in data our data is not trimmed.\n",
    "df.replace('^\\s+', '', regex=True, inplace=True) #front\n",
    "df.replace('\\s+$', '', regex=True, inplace=True) #end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the data types of sg, al, su, pcv, wbccc, rbcc as per data definition\n",
    "# df['sg']=df['sg'].astype('object')\n",
    "# df['al']=df['al'].astype('object')\n",
    "# df['su']=df['su'].astype('object')\n",
    "\n",
    "# new code\n",
    "listObjectType=['sg','al','su']\n",
    "for column in listObjectType:\n",
    "    df[column]=df[column].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bp'].head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing unique values of category columns\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == np.object:\n",
    "        print(column,\" object \",df[column].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "        print(column,\" non object \",df[column].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier treatment it is an medical record and data cannot be treated as outlier but how ever the reading of sodium and potassium is unrealistic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "j=1\n",
    "for i in ['sod','pot']:\n",
    "    plt.subplot(4,3,j)\n",
    "    sns.boxplot(x=df[i])\n",
    "    j=j+1\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is an data entry problem as its practically not possible to have such readings for humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sodium value min ', df['sod'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sodium level can never drop to such low levels as 4.5 in humans so treating it as an  outlier and setting as null "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sod'].replace({4.5:np.nan},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pot has two extream values on right which is not practically possible and setting this as null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Potasium extream value value', df['pot'].sort_values(ascending=False).head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pot'].replace({47.0:np.nan,39.0:np.nan},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now they are in limit\n",
    "plt.figure(figsize=(20,15))\n",
    "j=1\n",
    "for i in ['sod','pot']:\n",
    "    plt.subplot(4,3,j)\n",
    "    sns.boxplot(x=df[i])\n",
    "    j=j+1\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numDF=df.select_dtypes(include='number')\n",
    "catDF=df.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputedDF=df.copy()\n",
    "for column in catDF:\n",
    "    imputedDF[column] = LabelEncoder().fit_transform(df[column].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numDF:\n",
    "    imputedDF[column] = LabelEncoder().fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in imputedDF.columns:\n",
    "        print(column,\" non object \",imputedDF[column].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories have been imputed in KNN manner so need to be rounded of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding of the data.\n",
    "for column in catDF:\n",
    "    round(imputedDF[column],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection \n",
    "# Independent Data should be strongly connected to the target data\n",
    "# To avoid Multicollinearity the Independent variables should not be inter-related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp=imputedDF.drop(['class'], axis=1)\n",
    "out=imputedDF['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anovaDF=pd.DataFrame(f_classif(inp, out),columns=inp.columns).T.rename(columns={0:'f-statistic',1:'p-value'})\n",
    "anovaDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corelation of the features with the target variable\n",
    "ser=imputedDF.corr(method ='pearson')['class']\n",
    "ser.drop('class',inplace=True)\n",
    "\n",
    "ser.abs().plot.bar();\n",
    "\n",
    "plt.show(block=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcor=imputedDF.corr(method ='pearson')['class'].abs()\n",
    "pcor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcor=pcor.drop('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strongCor=list(pcor[pcor>.4].index)\n",
    "strongCor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(inp.corr(method ='pearson')[strongCor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp.corr(method ='pearson')[strongCor].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectHighCorr(data,treshold):\n",
    "    corr_col=set()\n",
    "    corrmat=data.corr(method ='pearson')\n",
    "    for i in range(len(corrmat.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corrmat.iloc[i,j])>treshold:\n",
    "                colname=corrmat.columns[i]\n",
    "                corr_col.add(colname)\n",
    "    return corr_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectHighCorr(inp,.6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
